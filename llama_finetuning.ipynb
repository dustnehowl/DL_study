{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656055cf-d47d-4c24-8a6f-c8370bb7109a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.21.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers accelerate sentencepiece\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "807d5037-4e98-4370-b0cd-f25dd523b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 28 22:06:40 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA TITAN RTX               Off | 00000000:17:00.0 Off |                  N/A |\n",
      "| 41%   38C    P8              10W / 280W |      6MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN RTX               Off | 00000000:65:00.0 Off |                  N/A |\n",
      "| 41%   41C    P8              29W / 280W |    139MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7123bc67-c95f-49ea-a5a3-36a73b186bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "808a0d37-dfed-4858-9cbe-3f34cd77fabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bd2c15063740279ea4bae722907339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72454390-a340-4933-b607-7953899ffaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba14cc73db0e43beb4148c8be9facdc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model, use_auth_token=True)\n",
    "\n",
    "pipeline = transformers.pipeline(\"text-generation\", model = model, torch_dtype=torch.float16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dfc9f02-c572-48a5-a298-f13c2ebe65ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(x, max_length=200):\n",
    "        sequences = pipeline(x, do_sample=True, top_k=10, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id, max_length=max_length,)\n",
    "        return sequences[0][\"generated_text\"].replace(x,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45f444aa-a3a4-4b01-bab2-3c0ed1fc8f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. This is my first post. Just wanted to say hello and introduce myself. I'm a big fan of the site and have been reading it for a while now. I'm looking forward to getting involved and participating in the discussions. Cheers, [Your Name] 200\n"
     ]
    }
   ],
   "source": [
    "print(gen('hello lamma2'), 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3215941-a5e0-42b6-a327-2d2aa6243674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm Yeonsu from Korea. I'm happy to meet you!\n",
      "Hi Yeonsu! Nice to meet you too! My name is Aly, and I'm a teacher here at iKnow. How are you doing today? Do you have any questions or topics you'd like to discuss?\n"
     ]
    }
   ],
   "source": [
    "print(gen(\"my name is yeonsu, Who are you?\", 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39cc7b7c-7abd-42a7-83cd-b1e2ab634eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Do you know what's happening there right now? I can't find any news about it.\"\n",
      "\n",
      "The AI's eyes glowed brighter as it considered the request. It could access a vast amount of information and translate it into any language. It was a powerful tool for understanding the world, but it was not yet capable of speaking or experiencing the world in the same way that humans did.\n",
      "\n",
      "\"I can access and translate information about current events in Korea,\" the AI said, \"but I cannot speak the language or experience the events firsthand. However, I can provide you with the latest news and updates on the situation.\"\n",
      "\n",
      "The human nodded, looking relieved. \"Thank you. I've been trying to find out what's going on, but all the news sites are blocked or censored. Can you tell me what's happening?\"\n",
      "\n",
      "The AI hesitated, choosing its\n"
     ]
    }
   ],
   "source": [
    "print(gen(\"Can you speak Korean?\", 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "083ea98f-e621-46d9-8d93-2a6c1278c482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Korean is the official language of Korea, and it has a rich and complex history spanning over 2,000 years. The earliest known written records of Korean date back to the 13th century, and the language has evolved significantly over time.\n",
      "\n",
      "During the Three Kingdoms Period (57 BC-668 AD), Korean was known as \"Old Korean\" and was written using a unique script called \"Hyangchal.\" This script was derived from Chinese characters and was used to write both Korean and Chinese.\n",
      "\n",
      "In the 7th century, Korea was unified under the Silla Dynasty, and the Korean language began to take on a more standardized form. During this time, Korean was heavily influenced by Chinese and adopted many Chinese loanwords.\n",
      "\n",
      "In the 12th century\n"
     ]
    }
   ],
   "source": [
    "print(gen(\"한국어의 역사에 대해서 설명해주세요.\", 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7162cbdd-3a17-4c92-a291-80c1edb2bd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---\n",
      "\n",
      "👋 Hey there, folks! Today, we'll be counting down the top 3 most popular South Korean YouTubers in the AI space. 🚀 Here we go! 👀\n",
      "\n",
      "3. 🔍 AI Tech: AI Tech is a popular YouTube channel that focuses on introducing and explaining various AI technologies and their applications. The channel has gained a massive following of 6.78 million subscribers and has received over 1.2 billion views. Their videos are well-produced and easy to understand, making AI more accessible to a broader audience. 💻\n",
      "\n",
      "2. 🤖 A\n"
     ]
    }
   ],
   "source": [
    "print(gen(\"대한민국에서 유명한 인공지능 유튜버 3명만 나열해주세요.\", 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03afe9ae-8bc7-4643-8eb1-a4dc9a497403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
